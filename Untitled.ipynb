{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from itertools import permutations, combinations, combinations_with_replacement\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "from scipy.stats import spearmanr, kruskal, ks_2samp\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data\\\\train_values.csv', index_col= 'sequence_id')\n",
    "labels = pd.read_csv('data\\\\train_labels.csv', index_col= 'sequence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_labels = pd.DataFrame(labels.values.argmax(axis = 1), index= labels.index)\n",
    "sparse_labels.columns = ['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {i:j for i,j in enumerate(labels.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_labels['cat'] = sparse_labels['num'].apply(lambda x: labels_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = sparse_labels['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sparse_labels['cat'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_sequence(data, n):\n",
    "\n",
    "    list_alpha = 'A C G N T'.split()\n",
    "    \n",
    "    permutation = set(''.join(p) for p in permutations(list_alpha * n, n))\n",
    "    df = pd.DataFrame(index = permutation)\n",
    "    num = 0\n",
    "\n",
    "    for dna in tqdm(data['sequence']):\n",
    "\n",
    "        end = len(dna) - (len(dna) % n) - 1\n",
    "        pro = []\n",
    "\n",
    "        for i in range(0, end, n):\n",
    "            codon = dna[i: i+n]\n",
    "            pro.append(codon)\n",
    "\n",
    "        df[num] = pd.Series(pro).value_counts()\n",
    "        num += 1\n",
    "\n",
    "    return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 63017/63017 [06:36<00:00, 158.75it/s]\n"
     ]
    }
   ],
   "source": [
    "n2 = dna_sequence(train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 63017/63017 [06:24<00:00, 163.70it/s]\n"
     ]
    }
   ],
   "source": [
    "n3 = dna_sequence(train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 63017/63017 [08:09<00:00, 128.63it/s]\n"
     ]
    }
   ],
   "source": [
    "n4 = dna_sequence(train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_seq = pd.concat([n2, n3], axis = 1)\n",
    "ngram_seq.index = train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_dna(dnastring):\n",
    "    table = {\n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'*', 'TAG':'*',\n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'*', 'TGG':'W',\n",
    "        }\n",
    "    protein = []\n",
    "    end = len(dnastring) - (len(dnastring) %3) - 1\n",
    "    for i in range(0,end,3):\n",
    "        codon = dnastring[i:i+3]\n",
    "        if codon in table:\n",
    "            aminoacid = table[codon]\n",
    "            protein.append(aminoacid)\n",
    "        else:\n",
    "            protein.append(\"X\")\n",
    "    return \"\".join(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_accuracy_scorer(estimator, X, y):\n",
    "    \"\"\"A custom scorer that evaluates a model on whether the correct label is in \n",
    "    the top 10 most probable predictions.\n",
    "\n",
    "    Args:\n",
    "        estimator (sklearn estimator): The sklearn model that should be evaluated.\n",
    "        X (numpy array): The validation data.\n",
    "        y (numpy array): The ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model as defined by the proportion of predictions\n",
    "               in which the correct label was in the top 10. Higher is better.\n",
    "    \"\"\"\n",
    "    # predict the probabilities across all possible labels for rows in our training set\n",
    "    probas = estimator.predict_proba(X)\n",
    "    \n",
    "    # get the indices for top 10 predictions for each row; these are the last ten in each row\n",
    "    # Note: We use argpartition, which is O(n), vs argsort, which uses the quicksort algorithm \n",
    "    # by default and is O(n^2) in the worst case. We can do this because we only need the top ten\n",
    "    # partitioned, not in sorted order.\n",
    "    # Documentation: https://numpy.org/doc/1.18/reference/generated/numpy.argpartition.html\n",
    "    top10_idx = np.argpartition(probas, -10, axis=1)[:, -10:]\n",
    "    \n",
    "    # index into the classes list using the top ten indices to get the class names\n",
    "    top10_preds = estimator.classes_[top10_idx]\n",
    "\n",
    "    # check if y-true is in top 10 for each set of predictions\n",
    "    mask = top10_preds == y.reshape((y.size, 1))\n",
    "    \n",
    "    # take the mean\n",
    "    top_10_accuracy = mask.any(axis=1).mean()\n",
    " \n",
    "    return top_10_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details(feature):\n",
    "    \n",
    "    columns = feature.columns\n",
    "    x = np.arange(len(columns))\n",
    "    percentage = list(round(100 * feature.sum(axis = 0)/ len(feature), 2))\n",
    "    variation = list(round(100* feature.var()/ feature.var().sum(), 2))\n",
    "    width = 0.40\n",
    "    \n",
    "    for column in columns:\n",
    "        feature = feature[feature[column] == 0]\n",
    "             \n",
    "    print(f'{len(feature)} values are in none of the categories')\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20,8))\n",
    "    rect1 = ax.bar(x - width/2, percentage, width, label = 'percentage')\n",
    "    rect2 = ax.bar(x + width/2, variation, width, label = 'variation')\n",
    "    #ax.set_grid()\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_title('Percentage and Variation')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(columns, rotation = 90)\n",
    "    ax.legend()\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "    autolabel(rect1)\n",
    "    autolabel(rect2)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_features(n, data, replacement = True):\n",
    "    \n",
    "    dna = ['A', 'C', 'G', 'N', 'T']\n",
    "    \n",
    "    if replacement == False:\n",
    "        permutation = set(''.join(p) for p in permutations(dna , n))\n",
    "    else:\n",
    "        permutation = set(''.join(p) for p in permutations(dna * n, n))\n",
    "\n",
    "    df = pd.DataFrame(index = data.index)\n",
    "    \n",
    "    for perm in tqdm(permutation):\n",
    "        df[perm] = data['sequence'].str.count(perm)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_none_column(data):\n",
    "    \n",
    "    new_data = data.copy()\n",
    "    name = data.name\n",
    "\n",
    "    for column in new_data.columns:\n",
    "        new_data = new_data[new_data[column] == 0]\n",
    "    \n",
    "    new_column = f'{name}_none'\n",
    "    \n",
    "    data[new_column] = float(0)\n",
    "    \n",
    "    for idx in new_data.index:\n",
    "        data.loc[idx, new_column] = float(1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ones(x): \n",
    "    if x > 1:\n",
    "        x = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_columns(data):\n",
    "\n",
    "    copy = data.copy()\n",
    "    \n",
    "    df = pd.DataFrame(index= data.index, dtype= 'float64')\n",
    "        \n",
    "    df[f'{data.name}_multi_2'] = float(0)\n",
    "        \n",
    "    for c in combinations(data.columns, 2):\n",
    "        \n",
    "        X = copy[list(c)]\n",
    "        idx = X[X.sum(axis = 1) == 2].index\n",
    "            \n",
    "        total_cases = len(idx)\n",
    "            \n",
    "        if total_cases > 0:\n",
    "            for j in idx:\n",
    "                df.loc[j, f'{data.name}_multi_2'] = float(1)\n",
    "         \n",
    "    if df[f'{data.name}_multi_2'].sum() == float(0):\n",
    "        df.drop(f'{data.name}_multi_2', axis = 1, inplace = True)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        index = df[df[column] > 0].index\n",
    "        for z in index:\n",
    "            copy.loc[z,:] = float(0)\n",
    "            \n",
    "    final = pd.concat([copy, df], axis = 1)\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_info(data):\n",
    "\n",
    "    df = pd.DataFrame(index= data.columns, columns= data.columns)\n",
    "\n",
    "    combination = combinations(data.columns, 2)\n",
    "    \n",
    "    print(f'Starting {(len(data.columns) * (len(data.columns) - 1))/2} iterations')\n",
    "    \n",
    "    for i in tqdm(combination):\n",
    "        df.loc[i[0], i[1]] = round(ks_2samp(data[i[0]].values, data[i[1]].values)[1], 3)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_dist(p_value, distribution_data):\n",
    "    \n",
    "    names = distribution_data.columns\n",
    "    data = distribution_data[distribution_data > p_value].notna()\n",
    "    combination = {}\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        row = data.values[i,:]\n",
    "        \n",
    "        for j in range(len(names)):\n",
    "            number = data.values[i,j]\n",
    "            \n",
    "            if number == True:\n",
    "                combination[(names[i], names[j])] = distribution_data.iloc[i,j]\n",
    "        \n",
    "    \n",
    "    return combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_similar_dict(p_value, distribution_data, stats_data):\n",
    "    scores_dict = similar_dist(p_value, distribution_data)\n",
    "    drop_list = []\n",
    "    \n",
    "    for i in scores_dict.keys():\n",
    "        name = stats_data.loc[list(i), 'f'].sort_values().index[0]\n",
    "        drop_list.append(name)\n",
    "    \n",
    "    return set(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_chi2_score(data, y, p_value = False):\n",
    "\n",
    "    if p_value == False:\n",
    "        print('Getting F-scores')\n",
    "        stats_data = pd.DataFrame(f_classif(data.values, y)[0], index= data.columns, columns= ['f'])\n",
    "        print('Getting Chi2-scores')\n",
    "        stats_data['chi2'] = pd.DataFrame(chi2(data.values, y)[0], index = data.columns)\n",
    "        \n",
    "    else:\n",
    "        stats_data = pd.DataFrame(f_classif(data.values, y)[1], index= data.columns, columns= ['f'])\n",
    "        stats_data['chi2'] = pd.DataFrame(chi2(data.values, y)[1], index = data.columns)\n",
    "    \n",
    "    return stats_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance = ['bacterial_resistance_ampicillin',\n",
    "       'bacterial_resistance_chloramphenicol',\n",
    "       'bacterial_resistance_kanamycin',\n",
    "       'bacterial_resistance_spectinomycin',\n",
    "       'bacterial_resistance_other']\n",
    "\n",
    "copy_number = ['copy_number_high_copy', 'copy_number_low_copy', 'copy_number_unknown']\n",
    "\n",
    "growth_strain = ['growth_strain_ccdb_survival', 'growth_strain_dh10b', \n",
    "       'growth_strain_neb_stable', 'growth_strain_dh5alpha',\n",
    "       'growth_strain_other', 'growth_strain_stbl3', 'growth_strain_top10',\n",
    "       'growth_strain_xl1_blue']\n",
    "\n",
    "growth_temp = ['growth_temp_37', 'growth_temp_30', 'growth_temp_other']\n",
    "\n",
    "selectable_markers = ['selectable_markers_blasticidin',\n",
    "       'selectable_markers_his3', 'selectable_markers_hygromycin',\n",
    "       'selectable_markers_leu2', 'selectable_markers_neomycin',\n",
    "       'selectable_markers_other', 'selectable_markers_puromycin',\n",
    "       'selectable_markers_trp1', 'selectable_markers_ura3',\n",
    "       'selectable_markers_zeocin']\n",
    "\n",
    "species_budding = ['species_budding_yeast', 'species_fly',\n",
    "       'species_human', 'species_mouse', 'species_mustard_weed',\n",
    "       'species_other', 'species_synthetic',\n",
    "       'species_zebrafish', 'species_nematode', 'species_rat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_df = train[bacterial_resistance]\n",
    "copy_number_df = train[copy_number]\n",
    "growth_strain_df = train[growth_strain]\n",
    "growth_temp_df = train[growth_temp]\n",
    "selectable_markers_df = train[selectable_markers]\n",
    "species_budding_df = train[species_budding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_df.name = 'bacterial_resistance'\n",
    "copy_number_df.name = 'copy_number'\n",
    "growth_strain_df.name = 'growth_strain'\n",
    "growth_temp_df.name = 'growth_temp'\n",
    "selectable_markers_df.name = 'selectable_markers'\n",
    "species_budding_df.name = 'species_budding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectable_markers_df = multiple_columns(selectable_markers_df)\n",
    "#species_budding_df = multiple_columns(species_budding_df)\n",
    "#copy_number_df = multiple_columns(copy_number_df)\n",
    "bacterial_resistance_df = multiple_columns(bacterial_resistance_df)\n",
    "growth_strain_df = multiple_columns(growth_strain_df)\n",
    "#growth_temp_df = multiple_columns(growth_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_df.name = 'bacterial_resistance'\n",
    "copy_number_df.name = 'copy_number'\n",
    "growth_strain_df.name = 'growth_strain'\n",
    "growth_temp_df.name = 'growth_temp'\n",
    "selectable_markers_df.name = 'selectable_markers'\n",
    "species_budding_df.name = 'species_budding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectable_markers_df = make_none_column(selectable_markers_df)\n",
    "species_budding_df = make_none_column(species_budding_df)\n",
    "#copy_number_df = make_none_column(copy_number_df)\n",
    "#bacterial_resistance_df = make_none_column(bacterial_resistance_df)\n",
    "#growth_strain_df = make_none_column(growth_strain_df)\n",
    "#growth_temp_df = make_none_column(growth_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bacterial_resistance_df.drop(['bacterial_resistance_spectinomycin'], axis = 1, inplace = True)\n",
    "#growth_strain_df.drop(['growth_strain_dh10b'], axis = 1, inplace = True)\n",
    "growth_temp_df.drop(['growth_temp_other'], axis = 1, inplace = True)\n",
    "#selectable_markers_df.drop(['selectable_markers_his3'], axis = 1, inplace = True)\n",
    "#species_budding_df.drop(['species_rat'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concat = [copy_number_df, growth_strain_df, growth_temp_df,\n",
    "          species_budding_df, bacterial_resistance_df, selectable_markers_df]\n",
    "features = pd.concat(concat, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features_drop_1 = ['selectable_markers_leu2', 'selectable_markers_his3', 'selectable_markers_trp1']\n",
    "features['selectable_markers_merge'] = features[features_drop_1].sum(axis = 1).apply(get_ones)\n",
    "features.drop(features_drop_1, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details(copy_number_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(abs(ngram.corr()), dtype=np.bool))\n",
    "plt.figure(figsize=(70,70))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(abs(ngram.corr()), cmap = cmap, square=True, mask = mask, vmax= 1, vmin= 0, annot = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spearman = pd.DataFrame(abs(spearmanr(ngram)[0]), columns= ngram.columns, index= ngram.columns)\n",
    "mask = np.triu(np.ones_like(spearman, dtype=np.bool))\n",
    "plt.figure(figsize=(70,70))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(spearman, cmap = cmap, square=True, mask = mask, vmax= 1, vmin= 0, annot = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(spearman[spearman.where(np.triu(spearman, k =1).astype(np.bool)) >= 0.985])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA EXTRACTION FROM SEQUENCE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:01<00:06,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "192it [00:22, 25.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:07<00:08,  2.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:13<00:07,  3.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:19<00:04,  4.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "ngram_1 = get_ngram_features(1, train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ngram_2 = get_ngram_features(2, train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_2.drop(ngram_2_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_3 = get_ngram_features(3, train, True)\n",
    "ngram_3 = pd.read_csv('output\\\\ngram_3_variables.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_3.drop(ngram_3_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3000it [02:50, 19.93it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#ngram_4 = get_ngram_features(4, train, False)\n",
    "ngram_4 = pd.read_csv('output\\\\ngram_4_variables.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_4_drop = pd.read_csv('ngram_4_drop.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_4.drop(ngram_4_drop.iloc[:,0].tolist(), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_5 = get_ngram_features(5, train, False)\n",
    "ngram_5 = pd.read_csv('output\\\\ngram_5_variables.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_5_drop = pd.read_csv('ngram_5_drop.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_5.drop(ngram_5_drop.iloc[:,0].tolist(), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dendrogram \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "corr = spearmanr(n).correlation\n",
    "corr_linkage = hierarchy.ward(corr)\n",
    "dendro = hierarchy.dendrogram(\n",
    "    corr_linkage, labels=n.columns, ax=ax1, leaf_rotation=90\n",
    ")\n",
    "dendro_idx = np.arange(0, len(dendro['ivl']))\n",
    "\n",
    "ax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro['ivl'], rotation='vertical')\n",
    "ax2.set_yticklabels(dendro['ivl'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 300.0 iterations\n"
     ]
    }
   ],
   "source": [
    "n2_dist = distribution_info(n2)\n",
    "n2_score = f_chi2_score(n2, y)\n",
    "ngram_2_drop = remove_similar_dict(0.05, n2_dist, n2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2.drop(ngram_2_drop, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 7750.0 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7750it [03:24, 37.97it/s]\n"
     ]
    }
   ],
   "source": [
    "n3_dist = distribution_info(n3)\n",
    "n3_score = f_chi2_score(n3, y)\n",
    "ngram_3_drop = remove_similar_dict(0.05, n3_dist, n3_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3.drop(ngram_3_drop, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n5 = pd.read_csv('output\\\\n5.csv', index_col= 0)\n",
    "#n5_score = pd.read_csv('output\\\\n5_score.csv', index_col= 0)\n",
    "#ngram_5_drop = remove_similar_dict(0.05, n5, n5_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ngram_4_drop).to_csv('ngram_4_drop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = distribution_info(n2)\n",
    "n2_score = f_chi2_score(ngram, y, False)\n",
    "ngram_2_drop = remove_similar_dict(0.05, n2, n2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2.drop(ngram_2_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlated variables remover\n",
    "\n",
    "spearman = pd.DataFrame(abs(spearmanr(ngram)[0]), columns= ngram.columns, index= ngram.columns)\n",
    "kr = spearman.where(np.triu(spearman, k = 1).astype('Bool'))\n",
    "\n",
    "names = spearman.columns\n",
    "df = kr[kr >= 0.99].notna()\n",
    "combination = {}\n",
    "    \n",
    "for i in range(len(names)):\n",
    "    row = df.values[i,:]\n",
    "        \n",
    "    for j in range(len(names)):\n",
    "        number = df.values[i,j]\n",
    "            \n",
    "        if number == True:\n",
    "            combination[(names[i], names[j])] = kr.iloc[i,j]\n",
    "            \n",
    "drop_list = []\n",
    "    \n",
    "for i in combination.keys():\n",
    "    name = n0_score.loc[list(i), 'f'].sort_values().index[0]\n",
    "    drop_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_drop = set(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = pd.read_csv('output//ngram_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram = pd.concat([ngram_1, ngram_seq], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ngram)\n",
    "n_scaled = scaler.transform(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63017, 130)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([features.values, n_scaled], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 45)\n",
    "\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_dev, y_dev,test_size = 0.5, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = KFold(6, True, 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree = ExtraTreesClassifier()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chi_score_tree = pd.DataFrame(tree.feature_importances_, index= ngram.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.bar(pd.concat([features,n]).columns, tree.feature_importances_)\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors= 40, weights= 'distance')\n",
    "#bag = BaggingClassifier(knn, 10, bootstrap_features = True)\n",
    "#nb= MultinomialNB(alpha= 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=40, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878133925737861"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_accuracy_scorer(knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1_scorer = make_scorer(f1_score, average = 'macro')\n",
    "accuracy_scorer = make_scorer(accuracy_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoring = {'f1': f1_scorer,\n",
    "          'accuracy_score': accuracy_scorer,\n",
    "          'top_10': top10_accuracy_scorer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val = cross_validate(knn, X, y, cv = fold, scoring = top10_accuracy_scorer, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data\\\\test_values.csv', index_col= 'sequence_id')\n",
    "submission = pd.read_csv('data\\\\submission_format_3TFRxH6.csv', index_col= 'sequence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_test = test[bacterial_resistance]\n",
    "copy_number_test = test[copy_number]\n",
    "growth_strain_test = test[growth_strain]\n",
    "growth_temp_test = test[growth_temp]\n",
    "selectable_markers_test = test[selectable_markers]\n",
    "species_budding_test = test[species_budding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_test.name = 'bacterial_resistance'\n",
    "copy_number_test.name = 'copy_number'\n",
    "growth_strain_test.name = 'growth_strain'\n",
    "growth_temp_test.name = 'growth_temp'\n",
    "selectable_markers_test.name = 'selectable_markers'\n",
    "species_budding_test.name = 'species_budding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectable_markers_test = multiple_columns(selectable_markers_test)\n",
    "#species_budding_test = multiple_columns(species_budding_test)\n",
    "#copy_number_test = multiple_columns(copy_number_test)\n",
    "bacterial_resistance_test = multiple_columns(bacterial_resistance_test)\n",
    "#growth_strain_test = multiple_columns(growth_strain_test)\n",
    "#growth_temp_test = multiple_columns(growth_temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_resistance_test.name = 'bacterial_resistance'\n",
    "copy_number_test.name = 'copy_number'\n",
    "growth_strain_test.name = 'growth_strain'\n",
    "growth_temp_test.name = 'growth_temp'\n",
    "selectable_markers_test.name = 'selectable_markers'\n",
    "species_budding_test.name = 'species_budding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectable_markers_test = make_none_column(selectable_markers_test)\n",
    "species_budding_test = make_none_column(species_budding_test)\n",
    "#copy_number_test = make_none_column(copy_number_test)\n",
    "#bacterial_resistance_test = make_none_column(bacterial_resistance_test)\n",
    "#growth_strain_test = make_none_column(growth_strain_test)\n",
    "#growth_temp_test = make_none_column(growth_temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_temp_test.drop(['growth_temp_other'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test = [copy_number_test, growth_strain_test, growth_temp_test,\n",
    "          species_budding_test, bacterial_resistance_test, selectable_markers_test]\n",
    "\n",
    "features_test = pd.concat(concat_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test['selectable_markers_merge'] = features_test[features_drop_1].sum(axis = 1).apply(get_ones)\n",
    "features_test.drop(features_drop_1, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_1_test = get_ngram_features(1, test, False)\n",
    "#ngram_1_test.drop(ngram_1_drop, axis = 1, inplace = True)\n",
    "\n",
    "ngram_2_test = get_ngram_features(2, test, False)\n",
    "#ngram_2_test.drop(ngram_2_drop, axis = 1, inplace = True)\n",
    "\n",
    "ngram_3_test = get_ngram_features(3, test, False)\n",
    "#ngram_3_test.drop(ngram_3_drop, axis = 1, inplace = True)\n",
    "\n",
    "ngram_4_test = get_ngram_features(4, test, False)\n",
    "\n",
    "ngram_5_test = get_ngram_features(5, test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = pd.concat([ngram_1_test, ngram_2_test, ngram_3_test, ngram_4_test, ngram_5_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_test = n_test[ngram.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(n_test.columns) == list(ngram.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_test = scaler.transform(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = features_test[features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.concatenate([features_test.values, ngram_test], axis = 1)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[1] == test_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = knn.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = knn.classes_ == submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_knn = pd.DataFrame(predictions_knn, columns= knn.classes_, index= submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_not_included = 1314 - predictions_knn.shape[1]\n",
    "non_included_col = np.zeros((predictions_knn.shape[0], num_not_included))\n",
    "\n",
    "test_col = []\n",
    "for i in submission.columns:\n",
    "    if i not in knn.classes_:\n",
    "        test_col.append(i)\n",
    "\n",
    "assert len(test_col) == num_not_included\n",
    "\n",
    "\n",
    "non_include_df = pd.DataFrame(non_included_col, columns = test_col, index = submission.index)\n",
    "submission_final = pd.concat([submission_knn, non_include_df], axis = 1)\n",
    "submission_final = submission_final[submission.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_knn.to_csv('submission_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('submission_new.zip', 'w', zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write('submission_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [0,2,6,7,8,9,10,11,14,18,19,20,21,23,24,25,26,27,29,30,32,33,34,37,39,41,42,43,45,46,48]\n",
    "\n",
    "title = ['copy_number_high_copy', 'copy_number_low_copy', 'copy_number_unknown','copy_number_none', 'growth_strain_ccdb_survival',\n",
    "'growth_strain_dh10b', 'growth_strain_neb_stable','growth_strain_dh5alpha', 'growth_strain_other', 'growth_strain_stbl3','growth_strain_top10', 'growth_strain_xl1_blue',\n",
    "'growth_strain_multi_2', 'growth_strain_none', 'growth_temp_37','growth_temp_30', 'growth_temp_other', 'growth_temp_none',\n",
    "'species_budding_yeast', 'species_fly', 'species_human','species_mouse', 'species_mustard_weed', 'species_other',\n",
    "'species_synthetic', 'species_zebrafish', 'species_nematode','species_rat', 'species_budding_multi_2', 'species_budding_none',\n",
    "'bacterial_resistance_ampicillin','bacterial_resistance_chloramphenicol','bacterial_resistance_kanamycin', 'bacterial_resistance_spectinomycin',\n",
    "'bacterial_resistance_other', 'bacterial_resistance_multi_2','bacterial_resistance_none', 'selectable_markers_blasticidin',\n",
    "'selectable_markers_his3', 'selectable_markers_hygromycin','selectable_markers_leu2', 'selectable_markers_neomycin',\n",
    "'selectable_markers_other', 'selectable_markers_puromycin','selectable_markers_trp1', 'selectable_markers_ura3',\n",
    "'selectable_markers_zeocin', 'selectable_markers_multi_2','selectable_markers_none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.iloc[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = []\n",
    "for i in idx:\n",
    "    inc.append(title[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features_score.index:\n",
    "    if i in inc:\n",
    "        features_score.loc[i, 'included'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_score.drop('included', inplace = True, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
